<!DOCTYPE html>
<html lang = "en">
    <head>
        <link rel = "stylesheet" type = "text/css" href="style.css">
        <title>CS766-Project</title>
    </head>
    <body>
        <header>
            <nav>
                <div class = "row">
                    <ul class = "main-nav">
                        <li><a href = index.html#Motivation>Motivation</a></li>
                        <li><a href = index.html#Approach>Approach</a></li>
                        <li><a href = index.html#Implementation>Implementation</a></li>
                        <li><a href = index.html#Results>Results</a></li>
                    </ul>
                </div>
            </nav>
            <div class = "webpage-head">
                <h1>Standing in Your Favorite Paintings!</h1>
            </div>
        </header>
        <div class = "member-info">Group Members: Bin Guo, Wei Tang, Yusong Yang</div>
        <section class="webbody">
            <div id = "Motivation">
                <h2>Motivation</h2>
                <p>Image style transfer is a topic that receives increasing research and application interests during these years. The term image style transfer, or alternatively image stylization, refers to the image processing task that extracts the feature of style of a set of images, and apply such style onto another set of images.</p>
                <p>There has been many implementations of image style transfer. One good example is transferring the style of an oil painting to a photograph, as shown below:</p> 
                <img src="imgs/figure1.jpg" alt = "sytlization example" class = "center">
                <figcaption class = "caption">Figure 1. An example of common image stylization. The landscape photograph is <br>transferred into 'Starry Night' style perfectly.</figcaption>
                
                <p>Although this kind of style transfer operation has achieved good performance when the to-be-stylized images are landscape photographs, it sometimes meet limitations when the photographs contain other elements, for example, a photo that contains a portrait. The next figure shows an example of undesired style transfer result:</p>
                <img src="imgs/figure2.jpg" alt="bad style transfering example" class="center">
                <figcaption class = "caption">Figure 2. An example of undesired image stylization.</figcaption>
                
                <p>The original photo is a man laying on a couch, and is transferred into The Starry Night style. However, the man’s figure becomes strange and unobvious after the style transfer. It is hard to tell there is a man laying in the right hide side image, if not given the original photograph. Besides, the face of this man becomes unrecognizable (replaced by a star) after the style transfer. </p>
                <p>By noticing this issue, we come up with the idea that developing a better image style transfer method for photograph that contains both portrait and landscape. The implementation consists of two major parts, first we need to extract the portrait out of the photograph, and second, apply different style transfer on portrait and landscape separately, and later combining them together. By choosing suitable parameters, the entire photo should be stylized, with the portrait still being recognizable. The first part of our project idea focus on portrait segmentation, and the second part focus on image stylization.</p>
            </div>

            <div id = "Approach">
                <h2>Approach</h2>
                <p>Our approach contais three main steps:</p>
                <ul class = "approach-list">
                    <li>1. Stylize the photograph with the style that specified by user.</li>
                    <li>2. Generate mask of portrait with portrait segmentation tool.</li>
                    <li>3. combine stylized photo with extracted portrait.</li>
                </ul>
                <p>Both stylization step and portrait segmentation step use Convolutional Neural Network(CNN), but not exatly the same network architecture. The details of implementations will be introduced in the next section.
                </p>
            </div>

            <div id = "Implementation">
                <h2>Implementation</h2>
                <ul class = "implementation-list">
                    <li>Image Stylization</li>
                    <p>We implement a style transfer tool by using a publicly distributed Convolutional Neural Network (CNN), VGG-19, which is constructed to perform object recognition. In CNN, the input is images, and at each layer, each image is represented as a set of representations, the object information is increasing explicit along the processing hierarchy.<br>
                    In our approach, a style picture and a content picture are given to a pre-trained CNN, VGG-19 and corresponding representation can be generated respectively. It is worth to note that the for content image, the representation is extracted from ‘conv4_1’ and style representation is extracted from ‘conv1_1’, ‘conv2_1’, ‘conv3_1’, ‘conv4_1’ and ‘conv5_1’. Then, we start with a noise image to generate the image and use the CNN to calculate the representation of the generated image. We calculate the L2 loss function against the style representation and content representation and denote them as style loss and content loss respectively. We do the optimization on this loss function and after some time of iterations to get a image that can either contain the maintain the content information and be stylized with specific image.</p>
                    <img class="center" src = "imgs/imple1.jpg" alt="implementation-style" style="width:50%">
                    <figcaption class = "caption">Figure 3. Principles of image stylization CNN.</figcaption>
                    <li>Portrait Segmentation</li>
<<<<<<< HEAD
                    <p>The potrait segmentation tool we implemented is a fully convolutional network (FCN) from Long et al. (2015). This FCN does dense prediction on each pixel and predicts the its probability of being part of the portrait. As shown in Fig. 4, the images used for training are all masked with correct portrait masks. The imput image will be processed and a heatmap will be outputed. In the heatmap, a value is assigned to each pixel, which represents the how likely it belongs to the potrait. Note that the heatmap is not normalized so that the summation of all predicted values may be larger than one.<br>
                    <br>
                    The training data included ~2700 labeled images which may contain one or more portrait objects. As for multiple objects in one image, they will be treated equally and we are not going to distinguish individual object from the rest.</p>
=======
                    <p>
                        The potrait segmentation tool we implemented is a fully convolutional network (FCN) from Long et al. (2015). This FCN does dense prediction on each pixel and predicts the its probability of being part of the portrait. As shown in Fig. 4, the images used for training are all masked with correct portrait masks. The imput image will be processed and a heatmap will be outputed. In the heatmap, a value is assigned to each pixel, which represents the how likely it belongs to the potrait. Note that the heatmap is not normalized so that the summation of all predicted values may be larger than one.
                    </p>
                    <p>
                        The training data included ~2700 labeled images which may contain one or more portrait objects. As for multiple objects in one image, they will be treated equally and we are not going to distinguish individual object from the rest.
                    </p>
>>>>>>> 800df40f35ac3238876ed70aec36669cec215f6c
                    
                    <img class="center" src = "imgs/imple2.jpg" alt="implementation-segmentation" style="width:50%">
                    <figcaption class = "caption">Figure 4. Principles of portrait segmentation CNN.</figcaption>
                </ul>
            </div>
            <div id = "Results">
                <h2>Results</h2>
                <ul class = "result">
                    <li>Image Stylization: the effect of epoches on stylization result</li>
                    <p>Firstly, we show how the number of iterations affects the stylization result, when the iteration count is from 0 to 200, 20 per frame. We can see that, initially, the output image is just random noise. When the number of iteration is increasing, the content of the image becomes more and more obvious, and the image becomes more and more stylized.</p>
                    <div class = "container">
                        <img src="imgs/style_epoch.jpg">
                        <img src = "imgs/20180503113930.gif">
                        <figcaption class = "caption">Figure 5. Effect of epoches on stylization result.</figcaption>
                    </div>
                    <p>The output at 200 epoches nicely explains our motivation: in the stylized photo, the portrait shows a strange, orange color. The details of portrait get lost, and the guy in the photo is not handsome! On the other hand, we really like this stylized background. So putting the original portrait into the stylized background is really a good solution!</p>
                    
                    <li>Image Stylization: the effect of content-style weight on stylization result</li>
                    <p>Below we show a set of images with different ratios between content weight and style weight. We can see that, when the content to style ratio is larger or equal to 1:1, there is really not too much difference between the output iamges.</p>
                    <img class = "center" src="imgs/diff_weights.jpg" alt = "different_weights" style="width: 60%">
                    <figcaption class = "caption">Figure 6. Effect of content-style weight on stylization.</figcaption>
                    
                    <li>Portrait Segmentation: the effect of training iterations on segmentation results</li>
                    <p>The original photo is Yusong (one of our teammates) standing in front of a bookshelf. This is not a task that can be easily segmented, since the photo is taken by iPhone, which means it has a large DOF; also the colors of the portrait is not apparently different from the background. We believe it is fair to use this photo as an example to show the perfermance of our portrait segmentation model, on an average case.<br>
                    <br>
                    The training epoch has a significant effect on the segmentation performance. When the number of training epoch is small, the generated mask has lot of areas that not actually belongs to the portrait. But when we use 100,000 epoches, the model can generate a perfect mask of the portrait for the original photo.</p>
                    <img class = "center" src="imgs/seg_diff.png" alt="different_segmentation" style="width: 60%">
                    <figcaption class = "caption">Figure 7. Effect of epoches on portrait segmentation result.</figcaption>
                    
                    <li>Put Them All Together: combine the segmented portrait with stylized background</li>
                    <p>In this section, we show sets of results that combine the segmented portrait with stylized backgound. In each set, the original photo, the chosen style and portrait mask are provided as the receipe of final output.</p>
                    <ul class = "combine-result-list">
                        <li>A combination of original portrait with Japanese-comic styled background:</li>
                        <img class = "center" src="imgs/final_out_1.jpg" alt="final_output_1" style="width: 60%;margin-top: 70px">
                        <figcaption class = "caption">Figure 8. Stylized backgound + original portraits.</figcaption>
                        
                        <li>A combination of comic-styled portrait with canvas-styled background:</li>
                        <img class = "center" src="imgs/final_out_2.jpg" alt = "final_output_2" style="width: 60%;margin-top: 70px">
                        <figcaption class = "caption">Figure 9. Stylized backgound + stylized portraits.</figcaption>
                        
                        <li>And finally, the photos of our team!</li>
                        <img class = "center" src="imgs/final_out_3.jpg" alt="final_output_3" style="width: 60%;margin-top: 70px">
                        <figcaption class = "caption">Figure 10. Our photos.</figcaption>
                        <br>
                        <br>
                    </ul>
                </ul>
            </div>
            
            <div id="reference">
                <h3>References</h3>
                <ul class="reference-list">
                    <li>Gatys, L. A., Ecker, A. S., & Bethge, M. (2015). A neural algorithm of artistic style. arXiv preprint arXiv:1508.06576.</li>
                    <li>Long, J., Shelhamer, E., & Darrell, T. (2015). Fully convolutional networks for semantic segmentation. In Proceedings of the IEEE conference on computer vision and pattern recognition (pp. 3431-3440).</li>
                    <li>Shen, X., Hertzmann, A., Jia, J., Paris, S., Price, B., Shechtman, E., & Sachs, I. (2016, May). Automatic portrait segmentation for image stylization. In Computer Graphics Forum (Vol. 35, No. 2, pp. 93-102).</li>
                </ul>
                <br><br>
            </div>
        </section>
        
        <div class="footer">
            <p style="padding: 20px 20px;font-size: 15px">If you have any question regarding this project or this webpage, please contact Wei Tang at wtang44 AT wisc dot edu.</p>
        </div>
    </body>
</html>
